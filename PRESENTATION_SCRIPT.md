# 평가 & 포상 시스템 발표 스크립트

> **발표 시간**: 4분 30초 ~ 5분
> **담당 기능**: 평가 시스템, 포상 시스템 (AI 추천 포함)
> **발표 구성**: PPT 발표 (4~5장) + 구현 실행 영상 설명

---

## 타임라인 요약

| 시간 | 구분 | 내용 |
|------|------|------|
| 0:00 ~ 0:15 | PPT | 슬라이드 1 - 담당 기능 소개 |
| 0:15 ~ 0:50 | PPT | 슬라이드 2 - 평가 시스템 구조 |
| 0:50 ~ 1:30 | PPT | 슬라이드 3 - 포상 시스템 구조 |
| 1:30 ~ 2:20 | PPT | 슬라이드 4 - AI 추천 핵심 기술 |
| 2:20 ~ 2:40 | PPT | 슬라이드 5 - 기술 스택 & 아키텍처 |
| 2:40 ~ 4:30 | 영상 | 구현 실행 영상 보면서 설명 |

---

## [파트 1] PPT 발표 (0:00 ~ 2:40)

---

### 슬라이드 1 - 담당 기능 소개 (0:00 ~ 0:15)

**PPT 내용**: 담당자 이름, 담당 기능 (평가 시스템 / 포상 시스템 / AI 추천)

```
저는 평가와 포상 기능을 담당했습니다.

평가 시스템, 포상 시스템,
그리고 한국어 BERT 모델을 활용한
AI 포상 추천 기능까지 구현했습니다.
```

---

### 슬라이드 2 - 평가 시스템 구조 (0:15 ~ 0:50)

**PPT 내용**:
- 평가 프로세스 흐름도 (항목 관리 → 평가 입력 → 평가 조회)
- 권한 체계 표 (CEO / LEADER / EMP)
- 점수 계산 공식 & 등급 기준

```
평가 시스템은 세 가지 기능으로 구성됩니다.

첫째, 평가 항목 관리입니다.
업무수행능력, 협업능력 같은 항목과 가중치를 설정합니다.
이 기능은 평가 관리자와 CEO만 접근 가능합니다.

둘째, 평가 입력입니다.
직급에 따라 평가 대상이 자동으로 필터링됩니다.
CEO는 LEADER를, LEADER는 본인 팀원을 평가합니다.
점수를 입력하면 가중치가 적용되어 총점이 자동 계산되고,
S부터 C까지 등급이 부여됩니다.

셋째, 평가 조회입니다.
사원은 본인이 받은 평가만 조회할 수 있습니다.
```

---

### 슬라이드 3 - 포상 시스템 구조 (0:50 ~ 1:30)

**PPT 내용**:
- 포상 프로세스 흐름도 (정책 관리 → 수동 추천 / AI 추천 → 승인 관리)
- 7가지 포상 유형 목록
- 수동 추천 vs AI 추천 비교

```
포상 시스템입니다.

포상 정책 관리에서는
프로젝트 MVP, 팀워크상, 기술 제안 채택 등
7가지 포상 유형을 관리합니다.

포상 후보 추천은 두 가지 방식이 있습니다.
수동 추천은 CEO나 LEADER가 직접 추천하는 방식이고,
AI 추천은 평가 데이터를 분석해서 자동으로 후보를 추천합니다.

매번 수동으로 추천하려면 평가 기록을 일일이 확인해야 하는데,
AI 추천이 이 과정을 자동화합니다.
이 AI 추천이 제가 가장 중점을 둔 부분입니다.
```

---

### 슬라이드 4 - AI 추천 핵심 기술 (1:30 ~ 2:20)

**PPT 내용**:
- 한국어 BERT (ko-sroberta) 모델 설명
- 하이브리드 스코어링: BERT 의미 유사도 70% + 키워드 매칭 30%
- Kiwipiepy 형태소 분석 역할
- 감정 분석으로 부정적 평가 자동 제외

```
AI 추천의 핵심 기술입니다.

첫째, 한국어 BERT 모델을 사용했습니다.
ko-sroberta라는 사전학습된 한국어 모델로
문장의 의미를 벡터로 변환합니다.

예를 들어 "프로젝트에 크게 기여했다"라는 평가와
"프로젝트 MVP"라는 포상 정책이
의미적으로 유사하다는 걸 AI가 파악합니다.

둘째, 하이브리드 스코어링 방식입니다.
BERT의 의미 유사도 70%와
키워드 매칭 점수 30%를 합산해서
최종 추천 점수를 계산합니다.

셋째, Kiwipiepy 형태소 분석기로
한글에서 명사, 동사, 형용사만 추출해서
정확한 키워드 분석을 수행합니다.

또한 감정 분석 기능으로
부정적인 평가를 받은 직원은
포상 추천에서 자동 제외됩니다.
```

---

### 슬라이드 5 - 기술 스택 & 아키텍처 (2:20 ~ 2:40)

**PPT 내용**:
- 시스템 아키텍처 다이어그램 (React ↔ Spring Boot ↔ Python Flask)
- 3단계 폴백 구조 (Python BERT → OpenAI API → 규칙 기반)
- 기술 스택 목록

```
시스템 아키텍처입니다.

프론트엔드는 React, 백엔드는 Spring Boot,
AI 서버는 Python Flask로 구성했습니다.

AI 추천은 별도의 Python 서버로 분리했는데,
PyTorch, BERT 같은 AI 라이브러리가
Python에서 가장 잘 지원되기 때문입니다.

또한 3단계 폴백 구조를 적용해서
Python 서버 장애 시 OpenAI API,
그마저도 실패하면 규칙 기반 매칭으로
서비스가 중단되지 않도록 했습니다.

그러면 실제 구현 화면을 영상으로 보여드리겠습니다.
```

---

## [파트 2] 구현 실행 영상 설명 (2:40 ~ 4:30)

> 영상을 틀어놓고 화면에 맞춰 설명합니다.
> 영상 촬영 시 아래 순서대로 녹화하면 됩니다.

---

### 영상 장면 1 - 평가 항목 관리 (2:40 ~ 2:55)

```
먼저 평가 항목 관리 화면입니다.

업무수행능력, 협업능력 같은 항목들이 보이고,
각 항목에 가중치가 설정되어 있습니다.
관리자 권한으로 항목 추가, 수정, 삭제가 가능합니다.
```

---

### 영상 장면 2 - 평가 입력 (LEADER 계정) (2:55 ~ 3:15)

```
LEADER 계정으로 로그인한 평가 입력 화면입니다.

본인 팀의 팀원만 평가 대상으로 표시되는 걸 볼 수 있습니다.
점수를 입력하면 가중치가 적용되어
총점이 자동 계산되고, 등급이 부여됩니다.

입력한 평가는 수정, 삭제도 가능합니다.
```

---

### 영상 장면 3 - 평가 조회 (사원 계정) (3:15 ~ 3:25)

```
사원 계정으로 로그인하면
본인이 받은 평가만 조회할 수 있습니다.

등급과 총점, 항목별 점수, 평가자의 코멘트를 확인할 수 있습니다.
```

---

### 영상 장면 4 - 포상 정책 관리 & 수동 추천 (3:25 ~ 3:40)

```
포상 정책 관리 화면에서는
7가지 포상 유형이 관리되고 있습니다.

수동 추천 화면에서는 대상자를 선택하고
포상 정책을 고른 뒤 추천 사유를 작성하면
포상 후보로 등록됩니다.
```

---

### 영상 장면 5 - AI 추천 목록 (3:40 ~ 4:00)

```
이제 AI 추천 화면입니다.

평가 데이터를 기반으로
AI가 각 직원별로 적합한 포상을 분석한 결과입니다.
매칭 점수와 추천 포상 유형이 표시됩니다.
```

---

### 영상 장면 6 - AI 추천 상세 (4:00 ~ 4:15)

```
상세 화면을 보시면,

평가에서 추출된 키워드와
각 포상 정책과의 매칭 점수,
그리고 AI가 생성한 추천 사유가 표시됩니다.

이 직원은 '프로젝트', '기여', '협업' 키워드가 추출되어
프로젝트 MVP와 팀워크상이 높은 점수로 추천되었습니다.
```

---

### 영상 장면 7 - AI 추천 승인 → 등록 & 마무리 (4:15 ~ 4:30)

```
관리자가 이 추천을 승인하면
포상 후보로 정식 등록됩니다.

수동 추천과 AI 추천이 구분되어 관리됩니다.

이상으로 평가와 포상 시스템 발표를 마치겠습니다.
감사합니다.
```

---

## 영상 녹화 순서 (체크리스트)

```
[녹화 전 준비]
[ ] Spring Boot 서버 실행
[ ] React 프론트엔드 실행
[ ] Python Flask AI 서버 실행 (python run.py)
[ ] BERT 모델 로드 완료 확인

[녹화 순서]
1. 평가 항목 관리 화면 (관리자 계정)
   - 항목 목록 보여주기, 추가/수정 시연

2. 평가 입력 화면 (LEADER 계정으로 전환)
   - 팀원 목록 확인, 점수 입력, 등급 자동 산정

3. 평가 조회 화면 (사원 계정으로 전환)
   - 본인 평가 결과 확인

4. 포상 정책 관리 화면 (관리자 계정)
   - 포상 유형 목록 보여주기

5. 수동 추천 화면
   - 대상자 선택 → 정책 선택 → 사유 작성 → 등록

6. AI 추천 목록 화면
   - AI 분석 결과 목록 보여주기

7. AI 추천 상세 화면
   - 키워드, 매칭 점수, 추천 사유 보여주기

8. AI 추천 승인 → 포상 등록
   - 승인 버튼 클릭 → 등록 확인
```

---

## PPT 슬라이드 구성 요약

| 슬라이드 | 제목 | 핵심 내용 |
|----------|------|-----------|
| 1 | 담당 기능 소개 | 이름, 평가/포상/AI 추천 담당 |
| 2 | 평가 시스템 | 프로세스 흐름도, 권한 체계표, 등급 기준 |
| 3 | 포상 시스템 | 포상 유형, 수동 vs AI 추천 비교 |
| 4 | AI 핵심 기술 | BERT, 하이브리드 스코어링, 형태소 분석, 감정 분석 |
| 5 | 아키텍처 & 기술 스택 | React-Spring-Flask 구조도, 폴백 구조 |

---

## 예상 질문 & 답변

### Q1. 왜 Python 서버를 따로 만들었나요?

```
PyTorch, Transformers 같은 AI 라이브러리가
Python 생태계에서 가장 잘 지원되기 때문입니다.

Spring Boot에서 직접 처리하는 것보다
Python으로 분리하는 게 개발 효율이 높았고,
나중에 AI 모델만 교체하기도 쉽습니다.
```

### Q2. BERT가 뭔가요?

```
구글이 개발한 자연어 처리 모델입니다.

기존 방식은 단어 하나하나를 개별적으로 분석했는데,
BERT는 문장 전체의 문맥을 이해합니다.

그래서 "프로젝트에 기여했다"라는 문장과
"프로젝트 MVP"라는 포상 정책이
의미적으로 유사하다는 걸 파악할 수 있습니다.
```

### Q3. 왜 BERT와 키워드 매칭을 같이 쓰나요?

```
BERT만 사용하면 의미는 파악하지만
정책에서 원하는 구체적인 키워드를 놓칠 수 있습니다.

반대로 키워드 매칭만 쓰면
동의어나 유사 표현을 놓칩니다.

그래서 BERT 70%, 키워드 30%로
두 방식의 장점을 결합했습니다.
```

### Q4. AI 서버가 죽으면 어떻게 되나요?

```
3단계 폴백 구조를 구현했습니다.

1단계: Python BERT 서버 호출
2단계: 실패 시 OpenAI API 호출
3단계: 둘 다 실패 시 규칙 기반 키워드 매칭

이렇게 해서 AI 서버 장애에도
서비스가 중단되지 않도록 했습니다.
```

### Q5. 형태소 분석은 왜 필요한가요?

```
한글은 "프로젝트를", "프로젝트에서", "프로젝트의"처럼
조사가 붙어서 같은 단어도 다르게 인식됩니다.

형태소 분석기로 조사를 제거하고
"프로젝트"라는 원형만 추출하면
정확한 키워드 매칭이 가능합니다.
```

---

## 발표 팁

| 항목 | 조언 |
|------|------|
| **PPT는 간결하게** | 텍스트 최소화, 도식/표 위주로 구성 |
| **영상 전환 멘트** | "그러면 실제 구현 화면을 영상으로 보여드리겠습니다" |
| **영상에서 포인터 사용** | 설명하는 부분을 마우스나 포인터로 가리키기 |
| **AI 부분에서 천천히** | 가장 차별화되는 포인트, 서두르지 말 것 |
| **수식 한 번 언급** | "BERT 70%, 키워드 30%" 강조 |
| **영상 끊기면** | PPT로 돌아가서 말로 설명 가능하도록 내용 숙지 |

---

**작성일**: 2026-01-27
**발표 예상 시간**: 4분 30초